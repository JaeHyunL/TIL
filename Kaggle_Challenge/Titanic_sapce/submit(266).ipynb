{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43539/4288931874.py:26: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_y[col] = test_y[col].fillna(train_modes[col])\n",
      "/tmp/ipykernel_43539/4288931874.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df.loc[spend_condition, 'CryoSleep'] = train_df.loc[spend_condition, 'CryoSleep'].fillna(True)\n",
      "/tmp/ipykernel_43539/4288931874.py:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  lambda x: x.fillna(x.mode()[0] if not x.mode().empty else False)\n",
      "/tmp/ipykernel_43539/4288931874.py:76: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(df[col].mode()[0])\n"
     ]
    }
   ],
   "source": [
    "# 우주타이타닉 문제\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "gender_df = pd.read_csv('data/names.csv')\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "\n",
    "test_y = pd.read_csv('data/test.csv')\n",
    "\n",
    "tmp_train_df = train_df.drop(columns=['Transported'])\n",
    "\n",
    "\n",
    "train_df[[\"Pass_gggg\", 'Pass_pp']] = train_df['PassengerId'].str.split('_', expand=True).astype(int)\n",
    "test_y[[\"Pass_gggg\", 'Pass_pp']] = test_y['PassengerId'].str.split('_', expand=True).astype(int)\n",
    "train_df[\"Family_Size\"] = train_df.groupby(\"Pass_gggg\")[\"PassengerId\"].transform(\"count\")\n",
    "test_y[\"Family_Size\"] = test_y.groupby(\"Pass_gggg\")[\"PassengerId\"].transform(\"count\")\n",
    "\n",
    "train_means = tmp_train_df.select_dtypes(include=['float64']).mean()  # 수치형 열 평균\n",
    "train_modes = tmp_train_df.select_dtypes(exclude=['number']).mode().iloc[0]  # 범주형 열 최빈값\n",
    "for col in train_means.index:\n",
    "    test_y[col] = test_y[col].fillna(train_means[col])\n",
    "\n",
    "for col in train_modes.index:\n",
    "    test_y[col] = test_y[col].fillna(train_modes[col])\n",
    "\n",
    "# 이렇게하면 130개중 80 개 살림림 \n",
    "spend_condition = (train_df['CryoSleep'].isnull()) & (train_df['RoomService'] == 0) & (train_df['Spa'] == 0) & (train_df['ShoppingMall'] == 0) & (train_df['FoodCourt'] == 0) \\\n",
    "& (train_df['VRDeck'] == 0)\n",
    "train_df.loc[spend_condition, 'CryoSleep'] = train_df.loc[spend_condition, 'CryoSleep'].fillna(True)\n",
    "\n",
    "\n",
    "train_df['Deck'] = train_df['Cabin'].str.split('/').str[0]\n",
    "train_df['Side'] = train_df['Cabin'].str.split('/').str[2]\n",
    "\n",
    "#  HomePlanet 결측값 최빈값으로 약 170개 제거\n",
    "dest_condition = (train_df['HomePlanet'].isnull()) & (train_df['Deck'] == 'A') | (train_df['Deck'] == 'B') | ( train_df['Deck'] == 'C')\n",
    "train_df.loc[dest_condition, 'HomePlanet'] = train_df.loc[dest_condition, 'HomePlanet'].fillna('Europa')\n",
    "dest_condition = (train_df['HomePlanet'].isnull()) & ((train_df['Deck'] == 'F'))\n",
    "train_df.loc[dest_condition, 'HomePlanet'] = train_df.loc[dest_condition, 'HomePlanet'].fillna('Earth')\n",
    "dest_condition = (train_df['HomePlanet'].isnull()) & ((train_df['Deck'] == 'G'))\n",
    "train_df.loc[dest_condition, 'HomePlanet'] = train_df.loc[dest_condition, 'HomePlanet'].fillna('Mars')\n",
    "\n",
    "# 음 ... \n",
    "train_df['HomePlanet'] = train_df.groupby('Pass_gggg')['HomePlanet'].transform(\n",
    "    lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'Earth')\n",
    ")\n",
    "\n",
    "train_df['CryoSleep'] = train_df.groupby('Deck')['CryoSleep'].transform(\n",
    "    lambda x: x.fillna(x.mode()[0] if not x.mode().empty else False)\n",
    ")\n",
    "\n",
    "test_y.loc[spend_condition, 'CryoSleep'] = test_y.loc[spend_condition, 'CryoSleep'].fillna(True)\n",
    "# test_y.loc[dest_condition, 'HomePlanet'] = test_y.loc[dest_condition, 'HomePlanet'].fillna('Europa')\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    # CryoSleep: 소비가 0이면 True\n",
    "    spend_condition = (df['CryoSleep'].isnull()) & (df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) == 0)\n",
    "    df.loc[spend_condition, 'CryoSleep'] = True\n",
    "    \n",
    "    df['Deck'] = df['Cabin'].str.split('/').str[0]\n",
    "    for deck, planet in [('A', 'Europa'), ('B', 'Europa'), ('C', 'Europa'), ('F', 'Earth'), ('G', 'Mars')]:\n",
    "        df.loc[df['HomePlanet'].isnull() & (df['Deck'] == deck), 'HomePlanet'] = planet\n",
    "    df['HomePlanet'] = df.groupby('Pass_gggg')['HomePlanet'].transform(\n",
    "        lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'Earth')\n",
    "    )\n",
    "    \n",
    "    # 숫자형 결측치: KNNImputer\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df[numeric_cols] = pd.DataFrame(imputer.fit_transform(df[numeric_cols]), columns=numeric_cols, index=df.index)\n",
    "    \n",
    "    # 나머지 범주형: 최빈값\n",
    "    for col in ['Destination', 'VIP']:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    df['Cabin'] = df['Cabin'].fillna('F/0/S')  # 기본값\n",
    "    return df\n",
    "\n",
    "train_df = fill_missing_values(train_df)\n",
    "test_y = fill_missing_values(test_y)\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "train_df[numeric_cols] = pd.DataFrame(\n",
    "    imputer.fit_transform(train_df[numeric_cols]), \n",
    "    columns=numeric_cols, \n",
    "    index=train_df.index\n",
    ")\n",
    "\n",
    "train_df['Age'] = train_df.groupby('Family_Size')['Age'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "\n",
    "train_df['HomePlanet'] = train_df['HomePlanet'].astype('category')\n",
    "train_df['HomePlanet'] = train_df['HomePlanet'].cat.codes\n",
    "\n",
    "train_df['Destination'] = train_df['Destination'].astype('category')\n",
    "train_df['Destination'] = train_df['Destination'].cat.codes\n",
    "\n",
    "train_df['Side'] = train_df['Side'].astype('category')\n",
    "train_df['Side'] = train_df['Side'].cat.codes\n",
    "\n",
    "train_df['Deck'] = train_df['Deck'].astype('category')\n",
    "train_df['Deck'] = train_df['Deck'].cat.codes\n",
    "\n",
    "train_df['SideDeck'] = train_df['Deck'] + train_df['Side']\n",
    "train_df['SideDeck'] = train_df['SideDeck'].astype('category')\n",
    "train_df['SideDeck'] = train_df['SideDeck'].cat.codes\n",
    "\n",
    "train_df['VIP'] = train_df['VIP'].astype(int)\n",
    "train_df['Transported'] = train_df['Transported'].astype(int)\n",
    "train_df['CryoSleep'] = train_df['CryoSleep'].astype(int)\n",
    "\n",
    "train_df['Cabin_Num'] = pd.to_numeric(train_df['Cabin'].str.split('/').str[1], errors='coerce')\n",
    "train_df['Cabin_Num_bin'] = pd.qcut(train_df['Cabin_Num'], q=5, duplicates='drop')\n",
    "\n",
    "\n",
    "luxury_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "train_df['Total_Spend'] = train_df[luxury_cols].sum(axis=1)\n",
    "train_df['Spend_Ratio'] = train_df['Total_Spend'] / (train_df['Age'] + 1)  # 0 나누기 방지\n",
    "\n",
    "\n",
    "test_y['Total_Spend'] = test_y[luxury_cols].sum(axis=1)\n",
    "test_y['Spend_Ratio'] = test_y['Total_Spend'] / (test_y['Age'] + 1)\n",
    "\n",
    "test_y['Cabin_Num'] = pd.to_numeric(test_y['Cabin'].str.split('/').str[1], errors='coerce')\n",
    "test_y['Cabin_Num_bin'] = pd.qcut(test_y['Cabin_Num'], q=5, duplicates='drop')\n",
    "\n",
    "test_y['Deck'] = test_y['Cabin'].str.split('/').str[0]\n",
    "test_y['Side'] = test_y['Cabin'].str.split('/').str[2]\n",
    "\n",
    "test_y['HomePlanet'] = test_y['HomePlanet'].astype('category')\n",
    "test_y['HomePlanet'] = test_y['HomePlanet'].cat.codes\n",
    "\n",
    "test_y['Destination'] = test_y['Destination'].astype('category')\n",
    "test_y['Destination'] = test_y['Destination'].cat.codes\n",
    "\n",
    "test_y['Side'] = test_y['Side'].astype('category')\n",
    "test_y['Side'] = test_y['Side'].cat.codes\n",
    "\n",
    "test_y['Deck'] = test_y['Deck'].astype('category')\n",
    "test_y['Deck'] = test_y['Deck'].cat.codes\n",
    "\n",
    "test_y['SideDeck'] = test_y['Deck'] + test_y['Side']\n",
    "test_y['SideDeck'] = test_y['SideDeck'].astype('category')\n",
    "test_y['SideDeck'] = test_y['SideDeck'].cat.codes\n",
    "\n",
    "test_y['VIP'] = test_y['VIP'].astype(int)\n",
    "test_y['CryoSleep'] = test_y['CryoSleep'].astype(int)\n",
    "\n",
    "# 로그 변환 적용\n",
    "train_df['Total_Spend'] = train_df['Total_Spend'].apply(lambda x: np.log1p(x))\n",
    "train_df['Spend_Ratio'] = train_df['Spend_Ratio'].apply(lambda x: np.log1p(x))\n",
    "\n",
    "test_y['Total_Spend'] = test_y['Total_Spend'].apply(lambda x: np.log1p(x))\n",
    "test_y['Spend_Ratio'] = test_y['Spend_Ratio'].apply(lambda x: np.log1p(x))\n",
    "\n",
    "\n",
    "\n",
    "for col in luxury_cols:\n",
    "    train_df[col + \"_Ratio\"] = train_df[col] / (train_df[\"Total_Spend\"] + 1)\n",
    "    test_y[col + \"_Ratio\"] = test_y[col] / (test_y[\"Total_Spend\"] + 1)\n",
    "\n",
    "\n",
    "train_df[\"Luxury_Spender\"] = (train_df[\"Total_Spend\"] > train_df[\"Total_Spend\"].median()).astype(int)\n",
    "test_y[\"Luxury_Spender\"] = (test_y[\"Total_Spend\"] > test_y[\"Total_Spend\"].median()).astype(int)\n",
    "\n",
    "# 혼자 온 손님 분류\n",
    "train_df[\"Is_Alone\"] = (train_df[\"Family_Size\"] == 1).astype(int)\n",
    "test_y[\"Is_Alone\"] = (test_y[\"Family_Size\"] == 1).astype(int)\n",
    "\n",
    "# 나이 군집화\n",
    "train_df[\"Age_Group\"] = pd.cut(train_df[\"Age\"], bins=[0, 12, 18, 30, 50, 100], labels=[0, 1, 2, 3, 4])\n",
    "test_y[\"Age_Group\"] = pd.cut(test_y[\"Age\"], bins=[0, 12, 18, 30, 50, 100], labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# 손님 비율\n",
    "train_df[\"Spend_Per_Person\"] = train_df[\"Total_Spend\"] / (train_df[\"Family_Size\"] + 1)\n",
    "test_y[\"Spend_Per_Person\"] = test_y[\"Total_Spend\"] / (test_y[\"Family_Size\"] + 1)\n",
    "\n",
    "# 극단 값 제거\n",
    "train_df[\"Total_Spend\"] = np.clip(train_df[\"Total_Spend\"], 0, train_df[\"Total_Spend\"].quantile(0.99))\n",
    "test_y[\"Total_Spend\"] = np.clip(test_y[\"Total_Spend\"], 0, test_y[\"Total_Spend\"].quantile(0.99))\n",
    "\n",
    "\n",
    "# 토론 뒤지다가 젠더 찾음\n",
    "train_df['FirstName'] = train_df['Name'].str.split(' ').str.get(0)\n",
    "train_df['LastName'] = train_df['Name'].str.split(' ').str.get(1)\n",
    "\n",
    "test_y['FirstName'] = test_y['Name'].str.split(' ').str.get(0)\n",
    "test_y['LastName'] = test_y['Name'].str.split(' ').str.get(1)\n",
    "\n",
    "train_df = train_df.merge(gender_df[['FirstName', 'Gender']], on='FirstName', how='left')\n",
    "train_df['Gender'] = train_df['Gender'].astype('category').cat.codes\n",
    "\n",
    "test_y = test_y.merge(gender_df[['FirstName', 'Gender']], on='FirstName', how='left')\n",
    "test_y['Gender'] = test_y['Gender'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m---> 11\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mTransported\n\u001b[1;32m     13\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransported\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "X = train_df.select_dtypes(include=['number'])\n",
    "y = train_df.Transported\n",
    "X = X.drop(columns=['Transported'])\n",
    "\n",
    "cat_model = CatBoostClassifier(iterations=500, learning_rate=0.04, depth=5, verbose=0)\n",
    "xgb_model = XGBClassifier(n_estimators=500, learning_rate=0.04, max_depth=3)\n",
    "svm_model = SVC(probability=True, kernel='rbf', C=1.0)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "\n",
    "estimators = [\n",
    "    ('cat', cat_model),\n",
    "    ('xgb', xgb_model),\n",
    "    ('svm', svm_model),\n",
    "    ('knn', knn_model)\n",
    "]\n",
    "model = StackingClassifier(estimators=estimators, final_estimator=GradientBoostingClassifier(n_estimators=100))\n",
    "test_y = test_y[X.columns].fillna(0)\n",
    "test_y = test_y.select_dtypes(include=['number'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 2. 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Validation에 대해 확신 높은 예측 선택 (여기서만 생성)\n",
    "val_proba = model.predict_proba(X_val)[:, 1]\n",
    "high_conf_mask = (val_proba > 0.95) | (val_proba < 0.05)\n",
    "\n",
    "pseudo_X = X_val[high_conf_mask]\n",
    "pseudo_y = (val_proba[high_conf_mask] > 0.55).astype(int)\n",
    "\n",
    "# 4. 원래 훈련셋과 결합\n",
    "X_pseudo = pd.concat([X_train, pseudo_X])\n",
    "y_pseudo = pd.concat([pd.Series(y_train), pd.Series(pseudo_y)])\n",
    "\n",
    "# 5. 새로 학습\n",
    "model.fit(X_pseudo, y_pseudo)\n",
    "\n",
    "# 6. 성능 확인\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Val accuracy after pseudo labeling:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# 7. 최종 테스트셋 예측\n",
    "final_pred = model.predict(test_y)\n",
    "\n",
    "\n",
    "# 0.8119575699132112  Spend Ratio 살렸을 때 값. \n",
    "# 0.8052073288331726  다 버렸을 때 값 .\n",
    "# Val accuracy after pseudo labeling: 0.81099324975892\n",
    "# 0.8066538090646095 \n",
    "# Val accuracy after pseudo labeling: 0.8085824493731919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId Transported\n",
      "0        0013_01        True\n",
      "1        0018_01       False\n",
      "2        0019_01        True\n",
      "3        0021_01        True\n",
      "4        0023_01        True\n",
      "...          ...         ...\n",
      "4272     9266_02        True\n",
      "4273     9269_01        True\n",
      "4274     9271_01        True\n",
      "4275     9273_01       False\n",
      "4276     9277_01        True\n",
      "\n",
      "[4277 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "template_df = pd.read_csv('data/test.csv')\n",
    "dd = template_df['PassengerId']\n",
    "\n",
    "# int(dd)\n",
    "ddf = pd.Series(final_pred, name='Transported')\n",
    "ddf = ddf.map({0: 'False', 1: 'True'})\n",
    "ds = pd.concat([dd ,ddf], axis=1)\n",
    "print(ds)\n",
    "ds.to_csv(\"result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
